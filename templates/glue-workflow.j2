AWSTemplateFormatVersion: '2010-09-09'

Description: >-
    The two workflows for processing RECOVER data. An outline of each workflow is below:

    (S3 to JSON) On-demand trigger (triggered by Lambda) ->
    (S3 to JSON) S3 to JSON

    and

    (JSON to Parquet) Scheduled trigger ->
    (JSON to Parquet) Crawler ->
    (JSON to Parquet) EnrolledParticipants and SymptomLog ->
    (JSON to Parquet) HealthKit ->
    (JSON to Parquet) Fitbit ->
    (JSON to Parquet) Google ->
    (JSON to Parquet) Garmin ->
    (JSON to Parquet) CompareParquetJob (if Namespace != "main")

Parameters:

  Namespace:
    Type: String
    Description: The namespace to which we write the datasets.

  JsonBucketName:
    Type: String
    Description: >-
      The name of the bucket where JSON datasets are stored.

  JsonKeyPrefix:
    Type: String
    Description: S3 key prefix where JSON datasets are stored.
    Default: json

  ParquetBucketName:
    Type: String
    Description: >-
      The name of the bucket where Parquet datasets are stored.

  ParquetKeyPrefix:
    Type: String
    Description: S3 key prefix where JSON datasets are stored.
    Default: parquet

  GlueDatabase:
    Type: String
    Description: >-
        Glue database containing Glue tables for use in JSON to Parquet job.

  CrawlerRole:
    Type: String
    Description: ARN of the IAM Role the crawler will assume.

  S3ToJsonJobName:
    Type: String
    Description: The name of the S3 To JSON Job

  JsontoParquetTriggerSchedule:
    Type: String
    Description: >-
        The cron schedule on which the JSON to Parquet workflow is triggered.
        When `IsMainNamespace`, the respective trigger is active from the moment
        of deployment. Otherwise, the trigger is disabled so that we don't waste
        resources running our development pipelines every day.
    Default: cron(0 2 * * ? *)

  CompareParquetStagingNamespace:
    Type: String
    Description: the name of the "staging" namespace

  CompareParquetMainNamespace:
    Type: String
    Description: The name of the "main" namespace

  S3SourceBucketName:
    Type: String
    Description: Name of the S3 bucket where source data are stored.

  CloudformationBucketName:
    Type: String
    Description: >-
        The name of the bucket where the cloudformation and artifacts are stored.

  ShareableArtifactsBucketName:
    Type: String
    Description: The name of the bucket where shareable artifacts are stored.

  ExpectationSuiteKeyPrefix:
    Type: String
    Description: The s3 key prefix of the expectation suite.

Conditions:
  IsMainNamespace: !Equals [!Ref Namespace, "main"]
  IsDevelopmentNamespace: !Not [!Equals [!Ref Namespace, "main"]]

Resources:

  {% set datasets = [] %}
  {% for v in sceptre_user_data.dataset_schemas.tables.keys() if not "Deleted" in v %}
    {% set dataset = {} %}
    {% do dataset.update({'data_type': v}) %}
    {% do dataset.update({'table_name': 'dataset_' + v.lower()}) %}
    {% do dataset.update({'stackname_prefix': '{}'.format(v.replace('_',''))}) %}
    {% do datasets.append(dataset) %}
  {% endfor %}

  S3ToJsonWorkflow:
    Type: AWS::Glue::Workflow
    Properties:
      DefaultRunProperties:
        namespace: !Ref Namespace
        json_bucket: !Ref JsonBucketName
        json_prefix: !Ref JsonKeyPrefix
      Description: >-
        Glue workflow for exporting raw data to their JSON datasets
      Name: !Sub ${Namespace}-S3ToJsonWorkflow

  S3ToJsonTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-S3ToJsonTrigger"
      Actions:
        - JobName: !Ref S3ToJsonJobName
      Description: This is the first trigger in the primary workflow.
      Type: ON_DEMAND
      WorkflowName: !Ref S3ToJsonWorkflow

  JsonToParquetWorkflow:
    Type: AWS::Glue::Workflow
    Properties:
      DefaultRunProperties:
        namespace: !Ref Namespace
        parquet_bucket: !Ref ParquetBucketName
        parquet_prefix: !Ref ParquetKeyPrefix
        glue_database: !Ref GlueDatabase
      Description: >-
        Glue workflow which loads the JSON datasets and writes to them to Parquet datasets
      MaxConcurrentRuns: 1
      Name: !Sub ${Namespace}-JsonToParquetWorkflow

  JsontoParquetTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-JsontoParquetTrigger"
      Actions:
        - CrawlerName: !Ref StandardCrawler
      Description: This trigger starts the JSON to Parquet workflow.
      Type: SCHEDULED
      Schedule: !Ref JsontoParquetTriggerSchedule
      StartOnCreation: !If [IsMainNamespace, true, false]
      WorkflowName: !Ref JsonToParquetWorkflow

  StandardCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Configuration: '{"Version":1.0,"CrawlerOutput":{"Partitions":{"AddOrUpdateBehavior":"InheritFromTable"}},"Grouping":{"TableGroupingPolicy":"CombineCompatibleSchemas"}}'
      DatabaseName: !Ref GlueDatabase
      Name: !Sub ${Namespace}-standard
      RecrawlPolicy:
        RecrawlBehavior: CRAWL_EVERYTHING
      Role: !Ref CrawlerRole
      SchemaChangePolicy:
        DeleteBehavior: LOG
        UpdateBehavior: LOG
      Targets:
        CatalogTargets:
        - DatabaseName: !Ref GlueDatabase
          Tables:
          {% for data_type in sceptre_user_data.dataset_schemas.tables.keys() %}
          - dataset_{{ data_type.lower() }}
          {% endfor %}

  CrawlerCompleteTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-CrawlerCompleteTrigger"
      Actions:
        {% for dataset in datasets if not "HealthKit" in dataset["data_type"] and not "Fitbit" in dataset["data_type"] and not "Google" in dataset["data_type"] and not "Garmin" in dataset["data_type"] %}
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
          Arguments: {"--glue-table": {{ "{}".format(dataset["table_name"]) }} }
        {% endfor %}
      Description: This trigger kicks off every JSON to Parquet job which is not associated with a device and runs after completion of the crawler.
      Type: CONDITIONAL
      Predicate:
        Conditions:
        - CrawlerName: !Ref StandardCrawler
          LogicalOperator: EQUALS
          CrawlState: SUCCEEDED
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow

  HealthKitTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-HealthKitTrigger"
      Actions:
        {% for dataset in datasets if "HealthKit" in dataset["data_type"] %}
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
          Arguments: {"--glue-table": {{ "{}".format(dataset["table_name"]) }} }
        {% endfor %}
      Description: This trigger kicks off every JSON to Parquet job which is associated with a HealthKit data type.
      Type: CONDITIONAL
      Predicate:
        Conditions:
          {% for dataset in datasets if not "HealthKit" in dataset["data_type"] and not "Fitbit" in dataset["data_type"] and not "Google" in dataset["data_type"] and not "Garmin" in dataset["data_type"] %}
          - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
            State: SUCCEEDED
            LogicalOperator: EQUALS
          {% endfor %}
        Logical: AND
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow

  FitbitTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-FitbitTrigger"
      Actions:
        {% for dataset in datasets if "Fitbit" in dataset["data_type"] %}
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
          Arguments: {"--glue-table": {{ "{}".format(dataset["table_name"]) }} }
        {% endfor %}
      Description: This trigger kicks off every JSON to Parquet job which is associated with a Fitbit data type.
      Type: CONDITIONAL
      Predicate:
        Conditions:
          {% for dataset in datasets if "HealthKit" in dataset["data_type"] %}
          - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
            State: SUCCEEDED
            LogicalOperator: EQUALS
          {% endfor %}
        Logical: AND
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow

  GoogleTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-GoogleTrigger"
      Actions:
        {% for dataset in datasets if "Google" in dataset["data_type"] %}
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
          Arguments: {"--glue-table": {{ "{}".format(dataset["table_name"]) }} }
        {% endfor %}
      Description: This trigger kicks off every JSON to Parquet job which is associated with a Google data type.
      Type: CONDITIONAL
      Predicate:
        Conditions:
          {% for dataset in datasets if "Fitbit" in dataset["data_type"] %}
          - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
            State: SUCCEEDED
            LogicalOperator: EQUALS
          {% endfor %}
        Logical: AND
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow

  GarminTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-GarminTrigger"
      Actions:
        {% for dataset in datasets if "Garmin" in dataset["data_type"] %}
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
          Arguments: {"--glue-table": {{ "{}".format(dataset["table_name"]) }} }
        {% endfor %}
      Description: This trigger kicks off every JSON to Parquet job which is associated with a Garmin data type.
      Type: CONDITIONAL
      Predicate:
        Conditions:
          {% for dataset in datasets if "Google" in dataset["data_type"] %}
          - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"]}}-Job
            State: SUCCEEDED
            LogicalOperator: EQUALS
          {% endfor %}
        Logical: AND
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow

  CompareParquetTrigger:
    Type: AWS::Glue::Trigger
    Condition: IsDevelopmentNamespace
    Properties:
      Name: !Sub "${Namespace}-CompareParquetTrigger"
      Actions:
        {% for dataset in datasets %}
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"] }}-CompareParquetJob
          Arguments:
            "--data-type": {{ "{}".format(dataset["table_name"]) }}
            "--main-namespace": !Ref CompareParquetMainNamespace
            "--staging-namespace": !Ref CompareParquetStagingNamespace
            "--input-bucket": !Ref S3SourceBucketName
            "--cfn-bucket": !Ref CloudformationBucketName
            "--parquet-bucket": !Ref ParquetBucketName
            "--additional-python-modules": "datacompy~=0.8 flask~=2.0 flask-cors~=3.0"
        {% endfor %}
      Description: This trigger runs the compare parquet jobs after completion of all JSON to Parquet jobs
      Type: CONDITIONAL
      Predicate:
        Conditions:
          {% for dataset in datasets if "Garmin" in dataset["data_type"] %}
          - JobName: !Sub "${Namespace}-{{ dataset["stackname_prefix"] }}-Job"
            State: SUCCEEDED
            LogicalOperator: EQUALS
          {% endfor %}
        Logical: AND
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow


  {% for dataset in datasets if dataset["data_type"].lower() in sceptre_user_data.data_values_expectations %}
  {{ dataset['stackname_prefix'] }}GreatExpectationsParquetTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Namespace}-{{ dataset['stackname_prefix'] }}GreatExpectationsParquetTrigger"
      Actions:
        - JobName: !Sub ${Namespace}-{{ dataset["stackname_prefix"] }}-GreatExpectationsParquetJob
          Arguments:
            "--data-type": {{ dataset["data_type"].lower() }}
            "--namespace": !Ref Namespace
            "--cfn-bucket": !Ref CloudformationBucketName
            "--parquet-bucket": !Ref ParquetBucketName
            "--shareable-artifacts-bucket": !Ref ShareableArtifactsBucketName
            "--expectation-suite-key-prefix": !Sub "${Namespace}/src/glue/resources/data_values_expectations.json"
            "--additional-python-modules": "great_expectations~=0.18,urllib3<2"
      Description:  This trigger runs the great expectation parquet job for this data type after completion of the JSON to Parquet job for this data type
      Type: CONDITIONAL
      Predicate:
        Conditions:
          - JobName: !Sub "${Namespace}-{{ dataset['stackname_prefix'] }}-Job"
            State: SUCCEEDED
            LogicalOperator: EQUALS
        Logical: AND
      StartOnCreation: true
      WorkflowName: !Ref JsonToParquetWorkflow
  {% endfor %}

Outputs:

  S3ToJsonWorkflowName:
    Value: !Ref S3ToJsonWorkflow
    Export:
      Name: !Sub '${AWS::Region}-${AWS::StackName}-S3ToJsonWorkflowName'
